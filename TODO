Things to do (a.k.a. "road map"):
---------------------------------

a) some simple GUI for full-text searching using SOLR

   1) for organizations:
      searching using name and surname, organization name or ICO
      facets: sro, no, ...

   2) ...
   
   n) this also means creating proper SOLR schema!

b) GUI for "advanced search" using SOLR syntax with some "prepared examples"
   (in a form of link: after link is clicked, search term is filled in and
   search results are updated - each field and data type should be covered, like
   "zakladne imanie: from 10 to 100 â‚¬" etc.)

c) find out the best value for 'datanest.organizations.batch_size', "best"
   meaning "quickest addition of all records into repository" - currently it
   takes around 6-8 hourse to add all items which slows down development and
   testing

d) adding more harvesters: direct harvesting of ORSR to get more data
   about companies, direct harvesting of procurement portals to have
   a shot by getting more data from the scanned documents themselves, ...

e) transform the existing application into something like container
   or whatever (maybe even using OSGI) so that it loads and runs
   Harvester and other components (as sort of plug-ins)

   i) at first, we need to only split the code into appropriate
      classes and packages, all in one project

   ii) later we can think about making it configurable so that ODN
       can be deployed in varying configurations (like somebody does
       not need certain harvesters and APIs so there would be a way to
       configure and deploy ODN to meet that criteria)

f) ...
