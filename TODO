Things to do (a.k.a. "road map"):
---------------------------------

a) update the RDF schema used in Sesame repository to be in line with proposal
   from Working Group PS1 of Slovak Standardization Committee associated with
   Ministry of Finance, see
   http://utopia.sk/wiki/pages/viewpage.action?pageId=32309648

b) Jackrabbit as back-end repository for:

   1) storage of whole "original" (as downloaded) documents:
   
      a) versioned: to have some audit trail
      b) caching: to be able to re-run harvesting/enhancements
         if we update our code without making a request to
         original source server
   
   2) storage of whole processed documents:
   
      a) for now, search GUI have nowhere to link to so this will also
         allow to make some presentation layer for the data we harvest
      
      b) further publication/replication of data: OAI-PMH, APIs, ...

c) document presentation layer: using processed documents from Jackrabbit - we
   need to implement "pages" which will display details about organizations, procurement,
   ... so that we can link to them (from search pages, from anywhere else)
   - needed feature: SOA friendly URLs like http://opendata.sk/dataset/organizations/<org_id>
     possibly with also http://opendata.sk/dataset/organizations/<ico> redirecting to
     .../<org_id>
   - idea: assuming processed documents are XML, we can employ XSLT to produce HTML

d) some simple GUI for full-text searching using SOLR

   1) for organizations:
      searching using name and surname, organization name or ICO
      facets: sro, no, ...

   2) ...
   
   n) this also means creating proper SOLR schema!

e) GUI for "advanced search" using SOLR syntax with some "prepared examples"
   (in a form of link: after link is clicked, search term is filled in and
   search results are updated - each field and data type should be covered, like
   "zakladne imanie: from 10 to 100 â‚¬" etc.)

f) find out the best value for 'datanest.organizations.batch_size', "best"
   meaning "quickest addition of all records into repository" - currently it
   takes around 6-8 hourse to add all items which slows down development and
   testing

g) adding more harvesters: direct harvesting of ORSR to get more data
   about companies, direct harvesting of procurement portals to have
   a shot by getting more data from the scanned documents themselves, ...

h) transform the existing application into something like container
   or whatever (maybe even using OSGI) so that it loads and runs
   Harvester and other components (as sort of plug-ins)

   i) at first, we need to only split the code into appropriate
      classes and packages, all in one project

   ii) later we can think about making it configurable so that ODN
       can be deployed in varying configurations (like somebody does
       not need certain harvesters and APIs so there would be a way to
       configure and deploy ODN to meet that criteria)

i) ...
